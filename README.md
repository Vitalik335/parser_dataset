ğŸš¨ Important Note: This is a project completed under tight deadlines. Due to time constraints, I was unable to collect all the data and polish the project. The main goal was to fulfill the assignment requirements as quickly as possible. ğŸš¨
ğŸŒ Open Data Web Scraper
This project is a simple web scraper designed to collect open data from government portals. It works for some websites, but due to the dynamic architecture of others (such as React-based websites), a different approach is required. Additionally, the project includes AnalyzeAI, a tool that processes the collected data using OpenAI to generate key insights.

ğŸ“Œ Supported Websites
âœ… ğŸ‡¬ğŸ‡§ data.gov.uk
âœ… ğŸ‡¦ğŸ‡º researchdata.edu.au
âœ… ğŸ‡¨ğŸ‡¦ search.open.canada.ca
âœ… ğŸ‡³ğŸ‡¿ data.govt.nz
âœ… ğŸ‡®ğŸ‡ª data.gov.ie

Some of these websites use dynamic content loading (e.g., with React), so a different scraping method (such as Selenium or Puppeteer) is needed instead of BeautifulSoup.

ğŸ” AnalyzeAI â€“ Data Processing with OpenAI
The AnalyzeAI script processes the datasets collected by the scraper and generates the following key information using OpenAI:

URL (link to the dataset)

Dataset Name

Topic (2-3 keywords/phrases)

ğŸ”§ Technologies Used
Python

BeautifulSoup / Scrapy â€“ For static HTML scraping

Selenium â€“ For scraping React-based websites with dynamic content

Requests â€“ To fetch web pages

Pandas â€“ For data processing

OpenAI API â€“ For dataset analysis

ğŸ“¦ Installation
It is highly recommended to set up a virtual environment for this project:

bash
Copy
Edit
python -m venv venv
source venv/bin/activate  # On macOS/Linux
venv\Scripts\activate  # On Windows
Then, install the necessary dependencies:

bash
Copy
Edit
pip install -r requirements.txt
ğŸš€ Usage
To run the scraper:
bash
Copy
Edit
type witch file do you want for example python parser.py
To run the AnalyzeAI script:
bash
Copy
Edit
python analyze_ai.py
ğŸ“œ License
This project is licensed under the MIT License.


